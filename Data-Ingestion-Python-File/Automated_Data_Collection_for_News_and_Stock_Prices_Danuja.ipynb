{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sQHil98sr7Wk","outputId":"aebc0701-1f8d-4a8a-c6fa-3e791eeb59d7"},"outputs":[{"output_type":"stream","name":"stdout","text":["ğŸš€ Starting Enhanced Finnhub Data Collection...\n","============================================================\n","ğŸ”„ Creating matched dataset...\n","âœ… Fetched 50 total articles, 23 relevant to tracked companies\n","ğŸ“Š Fetching prices for 10 companies...\n","âœ… AAPL (Apple): $207.57 (-1.48, -0.71%)\n","âœ… TSLA (Tesla): $308.27 (-10.77, -3.38%)\n","âœ… MSFT (Microsoft): $533.50 (+20.26, +3.95%)\n","âœ… GOOGL (Google): $191.90 (-4.63, -2.36%)\n","âœ… AMZN (Amazon): $234.11 (+3.92, +1.70%)\n","âœ… META (Meta): $773.44 (+78.23, +11.25%)\n","âœ… NVDA (NVIDIA): $177.87 (-1.40, -0.78%)\n","âœ… NFLX (Netflix): $1159.40 (-24.80, -2.09%)\n","âœ… CRM (Salesforce): $258.33 (-6.48, -2.45%)\n","âœ… PYPL (PayPal): $68.76 (-0.95, -1.36%)\n","\n","============================================================\n","ğŸ“Š ENHANCED MARKET DATA PREVIEW\n","============================================================\n","\n","ğŸ“ˆ MARKET OVERVIEW (2025-08-01)\n","Total Companies Tracked: 10\n","Companies with News Today: 5\n","Total News Articles: 23\n","Average Market Change: +0.38%\n","Biggest Gainer: META (Meta) +11.25%\n","Biggest Loser: TSLA (Tesla) -3.38%\n","\n","ğŸ“° NEWS HIGHLIGHTS\n","1. Exxon Mobil, Chevron say oil production is booming and theyâ€™re rolling in cash\n","   Companies: TSLA\n","   Source: MarketWatch | 2025-08-01 11:36:00\n","\n","2. How much are Southwest's new assigned seats? It depends\n","   Companies: TSLA\n","   Source: CNBC | 2025-08-01 11:00:01\n","\n","3. This trader is sounding the alarm over stocks. Why heâ€™s pressing the sell button now.\n","   Companies: AAPL\n","   Source: MarketWatch | 2025-08-01 10:42:00\n","\n","\n","ğŸ’¹ STOCK PERFORMANCE\n","ğŸ“‰ AAPL: $207.57 (-0.71%)\n","ğŸ“‰ TSLA: $308.27 (-3.38%)\n","ğŸ“ˆ MSFT: $533.50 (+3.95%)\n","ğŸ“‰ GOOGL: $191.90 (-2.36%)\n","ğŸ“ˆ AMZN: $234.11 (+1.70%)\n","\n","ğŸ’¾ Saving enhanced dataset...\n","âœ… Complete dataset saved: market_data_20250801_125225.json\n","âœ… News articles saved: news_articles_20250801_125225.csv\n","âœ… Stock prices saved: stock_prices_20250801_125225.csv\n","âœ… Summary report saved: daily_summary_20250801_125225.json\n","\n","âœ… Enhanced data collection completed!\n","\n","ğŸ“ Files created:\n","  â€¢ complete_dataset: market_data_20250801_125225.json\n","  â€¢ news_csv: news_articles_20250801_125225.csv\n","  â€¢ stocks_csv: stock_prices_20250801_125225.csv\n","  â€¢ summary_report: daily_summary_20250801_125225.json\n","\n","ğŸ¯ Ready for next steps:\n","  1. Use news CSV for sentiment analysis with Vertex AI\n","  2. Load stock CSV into BigQuery for correlation analysis\n","  3. Connect complete dataset to Looker Studio for dashboards\n","  4. Set up Apache Airflow to run this daily\n"]}],"source":["import requests\n","import json\n","from datetime import datetime, timedelta\n","import pandas as pd\n","import time\n","import re\n","import os\n","\n","class EnhancedFinnhubDataFetcher:\n","    def __init__(self, api_key):\n","        \"\"\"\n","        Enhanced Finnhub data fetcher with smart company matching\n","\n","        Args:\n","            api_key (str): Your Finnhub API key\n","        \"\"\"\n","        self.api_key = api_key\n","        self.base_url = \"https://finnhub.io/api/v1\"\n","        self.headers = {\"X-Finnhub-Token\": self.api_key}\n","\n","        # Define your company universe for focused analysis\n","        self.company_universe = {\n","            'AAPL': {'name': 'Apple', 'keywords': ['apple', 'iphone', 'ipad', 'mac', 'ios']},\n","            'TSLA': {'name': 'Tesla', 'keywords': ['tesla', 'elon musk', 'electric vehicle', 'ev', 'model s', 'model 3', 'model y']},\n","            'MSFT': {'name': 'Microsoft', 'keywords': ['microsoft', 'windows', 'azure', 'office', 'teams', 'xbox']},\n","            'GOOGL': {'name': 'Google', 'keywords': ['google', 'alphabet', 'youtube', 'android', 'chrome', 'search']},\n","            'AMZN': {'name': 'Amazon', 'keywords': ['amazon', 'aws', 'prime', 'alexa', 'bezos']},\n","            'META': {'name': 'Meta', 'keywords': ['meta', 'facebook', 'instagram', 'whatsapp', 'metaverse']},\n","            'NVDA': {'name': 'NVIDIA', 'keywords': ['nvidia', 'gpu', 'ai chip', 'graphics card']},\n","            'NFLX': {'name': 'Netflix', 'keywords': ['netflix', 'streaming', 'subscriber']},\n","            'CRM': {'name': 'Salesforce', 'keywords': ['salesforce', 'crm', 'cloud software']},\n","            'PYPL': {'name': 'PayPal', 'keywords': ['paypal', 'digital payment', 'fintech']}\n","        }\n","\n","    def fetch_market_news(self, category=\"general\", limit=100):\n","        \"\"\"\n","        Fetch market news headlines with enhanced metadata\n","\n","        Args:\n","            category (str): News category\n","            limit (int): Number of news articles to fetch\n","\n","        Returns:\n","            list: Enhanced news articles with company matching\n","        \"\"\"\n","        try:\n","            url = f\"{self.base_url}/news\"\n","            params = {\n","                \"category\": category,\n","                \"token\": self.api_key\n","            }\n","\n","            response = requests.get(url, params=params)\n","            response.raise_for_status()\n","\n","            raw_news = response.json()\n","\n","            if len(raw_news) > limit:\n","                raw_news = raw_news[:limit]\n","\n","            # Enhance news with company matching and metadata\n","            enhanced_news = []\n","            for article in raw_news:\n","                enhanced_article = self._enhance_news_article(article)\n","                if enhanced_article:  # Only keep articles related to our universe\n","                    enhanced_news.append(enhanced_article)\n","\n","            print(f\"âœ… Fetched {len(raw_news)} total articles, {len(enhanced_news)} relevant to tracked companies\")\n","            return enhanced_news\n","\n","        except requests.exceptions.RequestException as e:\n","            print(f\"âŒ Error fetching news: {e}\")\n","            return []\n","\n","    def _enhance_news_article(self, article):\n","        \"\"\"\n","        Enhance news article with company matching and sentiment preparation\n","        \"\"\"\n","        headline = article.get('headline', '').lower()\n","        summary = article.get('summary', '').lower()\n","        content = f\"{headline} {summary}\"\n","\n","        # Find matching companies\n","        matched_companies = []\n","        for symbol, company_data in self.company_universe.items():\n","            if self._matches_company(content, company_data['keywords']):\n","                matched_companies.append(symbol)\n","\n","        # Only return articles that match our company universe\n","        if not matched_companies:\n","            return None\n","\n","        # Enhance the article\n","        enhanced = {\n","            'id': article.get('id', f\"news_{datetime.now().timestamp()}\"),\n","            'headline': article.get('headline', ''),\n","            'summary': article.get('summary', ''),\n","            'source': article.get('source', 'Unknown'),\n","            'url': article.get('url', ''),\n","            'datetime': article.get('datetime', int(time.time())),\n","            'formatted_date': datetime.fromtimestamp(article.get('datetime', time.time())).strftime('%Y-%m-%d %H:%M:%S'),\n","            'matched_companies': matched_companies,\n","            'company_count': len(matched_companies),\n","            'category': article.get('category', 'general'),\n","            'sentiment_score': None,  # To be filled by sentiment analysis\n","            'sentiment_label': None,  # To be filled by sentiment analysis\n","            'content_length': len(article.get('headline', '') + article.get('summary', '')),\n","            'relevance_score': len(matched_companies) / len(self.company_universe)  # How many companies this affects\n","        }\n","\n","        return enhanced\n","\n","    def _matches_company(self, content, keywords):\n","        \"\"\"\n","        Check if content mentions company keywords\n","        \"\"\"\n","        for keyword in keywords:\n","            if keyword.lower() in content:\n","                return True\n","        return False\n","\n","    def fetch_stock_prices_for_universe(self):\n","        \"\"\"\n","        Fetch stock prices for all companies in our universe\n","\n","        Returns:\n","            list: Enhanced stock price data\n","        \"\"\"\n","        stock_data = []\n","\n","        print(f\"ğŸ“Š Fetching prices for {len(self.company_universe)} companies...\")\n","\n","        for symbol in self.company_universe.keys():\n","            price_data = self._fetch_enhanced_stock_price(symbol)\n","            if price_data:\n","                stock_data.append(price_data)\n","\n","            # Rate limiting\n","            time.sleep(0.2)\n","\n","        return stock_data\n","\n","    def _fetch_enhanced_stock_price(self, symbol):\n","        \"\"\"\n","        Fetch enhanced stock price data for a single symbol\n","        \"\"\"\n","        try:\n","            url = f\"{self.base_url}/quote\"\n","            params = {\n","                \"symbol\": symbol,\n","                \"token\": self.api_key\n","            }\n","\n","            response = requests.get(url, params=params)\n","            response.raise_for_status()\n","\n","            raw_data = response.json()\n","\n","            # Enhanced stock data\n","            current_price = raw_data.get('c', 0)\n","            previous_close = raw_data.get('pc', 0)\n","\n","            enhanced_stock = {\n","                'symbol': symbol,\n","                'company_name': self.company_universe[symbol]['name'],\n","                'current_price': current_price,\n","                'previous_close': previous_close,\n","                'change': raw_data.get('d', 0),\n","                'change_percent': raw_data.get('dp', 0),\n","                'high': raw_data.get('h', 0),\n","                'low': raw_data.get('l', 0),\n","                'open': raw_data.get('o', 0),\n","                'volume': raw_data.get('v', 0),\n","                'timestamp': datetime.now().isoformat(),\n","                'fetch_date': datetime.now().strftime('%Y-%m-%d'),\n","                'market_cap_estimate': current_price * 1000000000,  # Simplified estimate\n","                'volatility': abs(raw_data.get('dp', 0)),  # Using absolute percentage change as volatility proxy\n","                'trading_status': 'active' if current_price > 0 else 'inactive'\n","            }\n","\n","            print(f\"âœ… {symbol} ({self.company_universe[symbol]['name']}): ${current_price:.2f} ({enhanced_stock['change']:+.2f}, {enhanced_stock['change_percent']:+.2f}%)\")\n","            return enhanced_stock\n","\n","        except requests.exceptions.RequestException as e:\n","            print(f\"âŒ Error fetching {symbol}: {e}\")\n","            return {}\n","\n","    def create_matched_dataset(self):\n","        \"\"\"\n","        Create a perfectly matched dataset of news and stock prices\n","\n","        Returns:\n","            dict: Complete dataset ready for sentiment analysis and correlation\n","        \"\"\"\n","        print(\"ğŸ”„ Creating matched dataset...\")\n","\n","        # Fetch both news and stock data\n","        news_data = self.fetch_market_news(limit=50)\n","        stock_data = self.fetch_stock_prices_for_universe()\n","\n","        # Create matched records\n","        matched_dataset = {\n","            'fetch_timestamp': datetime.now().isoformat(),\n","            'fetch_date': datetime.now().strftime('%Y-%m-%d'),\n","            'total_news_articles': len(news_data),\n","            'total_companies_tracked': len(self.company_universe),\n","            'companies_with_news': len(set([company for article in news_data for company in article['matched_companies']])),\n","            'news_articles': news_data,\n","            'stock_prices': stock_data,\n","            'company_universe': self.company_universe\n","        }\n","\n","        # Generate summary statistics\n","        matched_dataset['summary'] = self._generate_summary_stats(news_data, stock_data)\n","\n","        return matched_dataset\n","\n","    def _generate_summary_stats(self, news_data, stock_data):\n","        \"\"\"\n","        Generate summary statistics for the dashboard\n","        \"\"\"\n","        # News statistics\n","        company_mentions = {}\n","        for article in news_data:\n","            for company in article['matched_companies']:\n","                company_mentions[company] = company_mentions.get(company, 0) + 1\n","\n","        # Stock statistics\n","        positive_movers = [s for s in stock_data if s.get('change_percent', 0) > 0]\n","        negative_movers = [s for s in stock_data if s.get('change_percent', 0) < 0]\n","\n","        return {\n","            'most_mentioned_company': max(company_mentions.items(), key=lambda x: x[1]) if company_mentions else ('None', 0),\n","            'total_company_mentions': sum(company_mentions.values()),\n","            'companies_with_news_today': len(company_mentions),\n","            'positive_movers': len(positive_movers),\n","            'negative_movers': len(negative_movers),\n","            'biggest_gainer': max(stock_data, key=lambda x: x.get('change_percent', 0)) if stock_data else None,\n","            'biggest_loser': min(stock_data, key=lambda x: x.get('change_percent', 0)) if stock_data else None,\n","            'average_change_percent': sum([s.get('change_percent', 0) for s in stock_data]) / len(stock_data) if stock_data else 0\n","        }\n","\n","    def save_enhanced_data(self, dataset, base_filename=\"market_data\"):\n","        \"\"\"\n","        Save enhanced dataset in multiple formats for different use cases\n","        \"\"\"\n","        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')\n","\n","        # Complete dataset (JSON) - for API integrations and cloud processing\n","        json_filename = f\"{base_filename}_{timestamp}.json\"\n","        with open(json_filename, 'w', encoding='utf-8') as f:\n","            json.dump(dataset, f, indent=2, ensure_ascii=False)\n","        print(f\"âœ… Complete dataset saved: {json_filename}\")\n","\n","        # News articles (CSV) - for sentiment analysis input\n","        if dataset['news_articles']:\n","            news_df = pd.DataFrame(dataset['news_articles'])\n","            news_csv = f\"news_articles_{timestamp}.csv\"\n","            news_df.to_csv(news_csv, index=False)\n","            print(f\"âœ… News articles saved: {news_csv}\")\n","\n","        # Stock prices (CSV) - for correlation analysis\n","        if dataset['stock_prices']:\n","            stocks_df = pd.DataFrame(dataset['stock_prices'])\n","            stocks_csv = f\"stock_prices_{timestamp}.csv\"\n","            stocks_df.to_csv(stocks_csv, index=False)\n","            print(f\"âœ… Stock prices saved: {stocks_csv}\")\n","\n","        # Summary report (JSON) - for dashboard overview\n","        summary_filename = f\"daily_summary_{timestamp}.json\"\n","        summary_data = {\n","            'date': dataset['fetch_date'],\n","            'summary': dataset['summary'],\n","            'company_universe': list(dataset['company_universe'].keys())\n","        }\n","        with open(summary_filename, 'w') as f:\n","            json.dump(summary_data, f, indent=2)\n","        print(f\"âœ… Summary report saved: {summary_filename}\")\n","\n","        return {\n","            'complete_dataset': json_filename,\n","            'news_csv': news_csv if dataset['news_articles'] else None,\n","            'stocks_csv': stocks_csv if dataset['stock_prices'] else None,\n","            'summary_report': summary_filename\n","        }\n","\n","    def display_preview(self, dataset):\n","        \"\"\"\n","        Display a preview of the matched dataset\n","        \"\"\"\n","        print(\"\\n\" + \"=\"*60)\n","        print(\"ğŸ“Š ENHANCED MARKET DATA PREVIEW\")\n","        print(\"=\"*60)\n","\n","        summary = dataset['summary']\n","\n","        print(f\"\\nğŸ“ˆ MARKET OVERVIEW ({dataset['fetch_date']})\")\n","        print(f\"Total Companies Tracked: {dataset['total_companies_tracked']}\")\n","        print(f\"Companies with News Today: {summary['companies_with_news_today']}\")\n","        print(f\"Total News Articles: {dataset['total_news_articles']}\")\n","        print(f\"Average Market Change: {summary['average_change_percent']:+.2f}%\")\n","\n","        if summary['biggest_gainer']:\n","            gainer = summary['biggest_gainer']\n","            print(f\"Biggest Gainer: {gainer['symbol']} ({gainer['company_name']}) +{gainer['change_percent']:.2f}%\")\n","\n","        if summary['biggest_loser']:\n","            loser = summary['biggest_loser']\n","            print(f\"Biggest Loser: {loser['symbol']} ({loser['company_name']}) {loser['change_percent']:.2f}%\")\n","\n","        print(f\"\\nğŸ“° NEWS HIGHLIGHTS\")\n","        for i, article in enumerate(dataset['news_articles'][:3], 1):\n","            companies = ', '.join(article['matched_companies'])\n","            print(f\"{i}. {article['headline']}\")\n","            print(f\"   Companies: {companies}\")\n","            print(f\"   Source: {article['source']} | {article['formatted_date']}\")\n","            print()\n","\n","        print(f\"\\nğŸ’¹ STOCK PERFORMANCE\")\n","        for stock in dataset['stock_prices'][:5]:\n","            status = \"ğŸ“ˆ\" if stock['change_percent'] > 0 else \"ğŸ“‰\" if stock['change_percent'] < 0 else \"â¡ï¸\"\n","            print(f\"{status} {stock['symbol']}: ${stock['current_price']:.2f} ({stock['change_percent']:+.2f}%)\")\n","\n","\n","def main():\n","    # Replace with your actual Finnhub API key from finnhub.io\n","    API_KEY = \"d2670ohr01qh25lm0e1gd2670ohr01qh25lm0e20\"\n","\n","    # Check if API key is still placeholder\n","    if API_KEY == \"YOUR_ACTUAL_API_KEY_HERE\":\n","        print(\"âŒ Please update the API_KEY variable with your actual Finnhub API key!\")\n","        print(\"1. Go to https://finnhub.io\")\n","        print(\"2. Sign up for free account\")\n","        print(\"3. Get your API key from dashboard\")\n","        print(\"4. Replace 'YOUR_ACTUAL_API_KEY_HERE' with your key\")\n","        return\n","\n","    # Initialize enhanced fetcher\n","    fetcher = EnhancedFinnhubDataFetcher(API_KEY)\n","\n","    print(\"ğŸš€ Starting Enhanced Finnhub Data Collection...\")\n","    print(\"=\"*60)\n","\n","    # Create matched dataset\n","    dataset = fetcher.create_matched_dataset()\n","\n","    # Display preview\n","    fetcher.display_preview(dataset)\n","\n","    # Save enhanced data\n","    print(\"\\nğŸ’¾ Saving enhanced dataset...\")\n","    saved_files = fetcher.save_enhanced_data(dataset)\n","\n","    print(\"\\nâœ… Enhanced data collection completed!\")\n","    print(\"\\nğŸ“ Files created:\")\n","    for file_type, filename in saved_files.items():\n","        if filename:\n","            print(f\"  â€¢ {file_type}: {filename}\")\n","\n","    print(f\"\\nğŸ¯ Ready for next steps:\")\n","    print(\"  1. Use news CSV for sentiment analysis with Vertex AI\")\n","    print(\"  2. Load stock CSV into BigQuery for correlation analysis\")\n","    print(\"  3. Connect complete dataset to Looker Studio for dashboards\")\n","    print(\"  4. Set up Apache Airflow to run this daily\")\n","\n","\n","if __name__ == \"__main__\":\n","    main()"]}]}